# HyC-LoRA: Memory Efficient Fine-tuning with Outlier-aware Hybrid Activation Compression

## News

* [07/05/2024] Release code.

## Usage

### Environment

Install the required packages:

```bash
pip install -r requirements.txt
```




## TODO

* [ ] Add ProSparse-LLaMA modeling code.
* [ ] Add LongLoRA finetuning of RedPajama dataset code.
* [ ] CUDA kernel optimization.
* [ ] Pure C/CUDA implementation on edge devices.

## Acknowledgement

Our code is build upon the following open-source projects:

* [GACT](https://github.com/LiuXiaoxuanPKU/GACT-ICML)
* [LoftQ](https://github.com/yxli2123/LoftQ)
* [LongLoRA](https://github.com/dvlab-research/LongLoRA)

We thank the authors for their open-sourced code.